{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwGaEb82PbWlcERQBk6RcM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthTiwari246/NeuralNetworks/blob/main/NameGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e4YpRXTkG9nM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('classic')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/male.txt', 'r') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "oLYSrbTyHO1i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data visualising\n",
        "print(f'Total Letters in the data : {len(data)}')\n",
        "vocab = sorted(set(list(data[:10_000])))\n",
        "vocab_length = len(vocab)\n",
        "print('\\n')\n",
        "print('Vocabulary Length : ',vocab_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYJ77CNiTrX-",
        "outputId": "fb4ab518-e1e8-47b8-d730-f5311bdcc1e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Letters in the data : 20293\n",
            "\n",
            "\n",
            "Vocabulary Length :  42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzchdeUBIVCx",
        "outputId": "91a9414f-68b3-4801-ff82-dd8e563e04fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n', '-', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = layers.StringLookup(vocabulary=vocab,\n",
        "                                     mask_token=None)\n",
        "\n",
        "chars_from_ids = layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(),\n",
        "                                     invert=True,\n",
        "                                     mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "iofzGL9OIYC8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = data.splitlines()\n",
        "names[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mGSTqy7JIqG",
        "outputId": "c6c1cc62-622b-4d03-df84-84d20ae0a51a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Aamir',\n",
              " 'Aaron',\n",
              " 'Abbey',\n",
              " 'Abbie',\n",
              " 'Abbot',\n",
              " 'Abbott',\n",
              " 'Abby',\n",
              " 'Abdel',\n",
              " 'Abdul',\n",
              " 'Abdulkarim']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(names, 'UTF-8'))\n",
        "all_ids[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJhHK7STI4Jo",
        "outputId": "0a80c1fa-045f-4515-b484-215b4ac92273"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[3, 17, 29, 25, 34], [3, 17, 34, 31, 30], [3, 18, 18, 21, 41],\n",
              " [3, 18, 18, 25, 21], [3, 18, 18, 31, 36], [3, 18, 18, 31, 36, 36],\n",
              " [3, 18, 18, 41], [3, 18, 20, 21, 28], [3, 18, 20, 37, 28],\n",
              " [3, 18, 20, 37, 28, 27, 17, 34, 25, 29]]>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,7))\n",
        "plt.hist([len(i) for i in all_ids])\n",
        "plt.show()\n",
        "max_length = max([len(i) for i in all_ids])\n",
        "print('\\n')\n",
        "print('Maximum Length : ', max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "DAVs4PBRNqsz",
        "outputId": "147301c9-f232-429d-9442-fd0fc081580b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1040x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Maximum Length :  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = []\n",
        "for i in all_ids:\n",
        "  ids_dataset.append(i)\n",
        "\n",
        "ids_dataset = pad_sequences(ids_dataset,\n",
        "                            maxlen=15,\n",
        "                            padding='pre')\n",
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(ids_dataset)"
      ],
      "metadata": {
        "id": "Ee2944t5NNbG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(1):\n",
        "  print(chars_from_ids(ids).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3p-fwIAOQJk",
        "outputId": "00679288-8075-4598-f98e-15e7fdc6743e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]' b'[UNK]'\n",
            " b'[UNK]' b'[UNK]' b'A' b'a' b'm' b'i' b'r']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "B4ZRnW4DOgw_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU-9RKJmPBWL",
        "outputId": "258c30df-57ce-4c78-b239-ecbc79e0284c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(1):\n",
        "  print(text_from_ids(ids).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3GSaYTwPEK5",
        "outputId": "408bc7b1-a941-4424-d026-8dae018bcf33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]Aamir'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ids_dataset.map(split_input_target)"
      ],
      "metadata": {
        "id": "XMfj22QHPmYY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDHQ82ZRPv3Z",
        "outputId": "1ed15dc5-cece-4613-e8f3-1e4ad4cdb55f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]Aami'\n",
            "Target: b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]Aamir'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(8_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suPp03nBP-pf",
        "outputId": "545fe45f-e4c5-4740-aa9c-ad2f5f7cd441"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 14), dtype=tf.int32, name=None), TensorSpec(shape=(None, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(ids_from_chars.get_vocabulary())"
      ],
      "metadata": {
        "id": "KLeXlf0nQXl_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = layers.GRU(rnn_units,\n",
        "                          return_sequences=True,\n",
        "                          return_state=True)\n",
        "    self.dense = layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "pRzc7FRGQ7qN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=128,\n",
        "    rnn_units=64)"
      ],
      "metadata": {
        "id": "2A6d1QzyRGop"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCwwlPYFRQve",
        "outputId": "93beb242-6166-4eb5-885e-8751034f69fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 14, 43) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx2cZHXtRYv-",
        "outputId": "5f5b39e9-14d4-4e47-ef13-c0f53a199cbf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  5504      \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  37248     \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  2795      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,547\n",
            "Trainable params: 45,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "nTt9p9nyRZu9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNfpC6cbRg_n",
        "outputId": "6717eba4-00ae-4044-d16f-2f4c0c98f1e8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6, 14, 10, 35, 29, 30,  3, 16, 32, 28,  5, 19, 22,  7])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4_qsszzRlTn",
        "outputId": "2bcbcf4f-579d-4079-c1cd-880eeb736fe8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]Benj'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'DLHsmnAPplCcfE'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "FGYJH5g7RtdO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wZrCghFRxfd",
        "outputId": "ae31e0df-718f-4053-b335-11ac18f3cb7d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (32, 14, 43)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(3.794983, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO__3L4kR84v",
        "outputId": "4200c819-bea0-499b-9dc0-25589d0e309b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.477474"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    monitor='loss',\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "izNhQezlR_wd"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSuwfEDeSVY-",
        "outputId": "8ee9a0d2-6a31-4d55-ff50-2ba361c71acc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "92/92 [==============================] - 3s 5ms/step - loss: 2.1571\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.3129\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.2010\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.1711\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.1467\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.1315\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.1181\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.1059\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0951\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0863\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0780\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0706\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0644\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0562\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0484\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0435\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0369\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0305\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 1.0259\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0186\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0126\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0067\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 1.0023\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9970\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9915\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9880\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9821\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9781\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9735\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9691\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9649\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 1s 8ms/step - loss: 0.9605\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 1s 8ms/step - loss: 0.9551\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9517\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9484\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9442\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9410\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9362\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9324\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9294\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9261\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9221\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9181\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9150\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9115\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9099\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9056\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9022\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8997\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8960\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8931\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8901\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8876\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8840\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8827\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8781\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8757\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8728\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8712\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8677\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8652\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8643\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8609\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8575\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8558\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8525\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8506\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8479\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8459\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8435\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.8419\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8388\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8363\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8351\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.8335\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8303\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8288\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8267\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8255\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8236\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8213\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8189\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8173\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8154\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8135\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8122\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8104\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8091\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8070\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8048\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8035\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8024\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.8004\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7994\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7974\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7956\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7940\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7926\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7914\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "2CbFQJWbSir0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "EyKfcGcZSlb9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Adam'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(7):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuoTx4o2So4U",
        "outputId": "b4d4a834-107c-4da5-f4ec-268dfe5406f5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adamandolph \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.03851175308227539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['andrew', 'marshall', 'margaret', 'jullian', 'jeniffer'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(6):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4E2t6KhSrl5",
        "outputId": "8a3db3de-26f0-4bb1-ef83-25317fb323db"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'andrewConton' b'marshallbastis' b'margarethnique' b'jullianPurPha'\n",
            " b'jenifferclahma'], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.7176797389984131\n"
          ]
        }
      ]
    }
  ]
}